<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[migle.me]]></title>
  <subtitle><![CDATA[一路走来，一路唱]]></subtitle>
  <link href="/atom.xml" rel="self"/>
  <link href="http://www.migle.me/"/>
  <updated>2014-05-13T04:26:01.816Z</updated>
  <id>http://www.migle.me/</id>
  
  <author>
    <name><![CDATA[migle]]></name>
    
  </author>
  
  <generator uri="http://zespia.tw/hexo/">Hexo</generator>
  
  <entry>
    <title><![CDATA[Hello World]]></title>
    <link href="http://www.migle.me/post/hello-world/"/>
    <id>http://www.migle.me/post/hello-world/</id>
    <published>2014-05-12T02:25:50.000Z</published>
    <updated>2014-05-13T03:47:49.000Z</updated>
    <content type="html"><![CDATA[<p>今天迁到 <a href="http://hexo.io" target="_blank">Hexo</a>!  ^_^  <a href="http://hexo.io/docs" target="_blank">documentation</a> to learn how to use.</p>
]]></content>
    
    
  </entry>
  
  <entry>
    <title><![CDATA[CDH5伪分布式环境搭建]]></title>
    <link href="http://www.migle.me/post/cdh5%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    <id>http://www.migle.me/post/cdh5伪分布式环境搭建/</id>
    <published>2014-04-30T05:59:23.000Z</published>
    <updated>2014-05-13T02:58:58.000Z</updated>
    <content type="html"><![CDATA[<h2 id="说明：">说明：</h2>
<ol>
<li><p>本文描述的是基于Windows+虚拟机+CentOS的Hadoop+HBase的开发环境搭建过程，使用的Hadoop版本是CDH5(Cloudera Distribution including Apache Hadoop，CDH)，旨在说明HADOOP的伪分布式环境搭建关键步骤。CDH5与Hadoop的关系，Hadoop、Hbase、Zookeeper之间的关系，及文中涉及的一些工具、命令的使用等与本文有关系不是特别密切的东西都没有详细说明,想了解更多请：<a href="http://www.google.com" target="_blank">http://www.google.com</a></p>
</li>
<li><p>本文旨在学习Hadoop,而且所有操作基本都是在虚拟机中进行，所以方便起见所有操作直接用root用户。</p>
</li>
</ol>
<h2 id="基础环境">基础环境</h2>
<h3 id="操作系统">操作系统</h3>
<p>CDH5的环境要求可以参见：<a href="http://www.cloudera.com/content/cloudera-content/cloudera-docs/CDH5/latest/CDH5-Requirements-and-Supported-Versions/CDH5-Requirements-and-Supported-Versions.html" target="_blank">CDH 5 Requirements and Supported Versions</a> 虚拟机可以用VMWare或VirtualBox，详细安装过程请自行Google ，本文所用的环境为Win8+VMWare+CentOS6.4 +CDH5以下是一些需要注意的点：</p>
<blockquote>
<blockquote>
<p>虚拟机安装CentOS6.4方便起见推荐使用安装minimal版，小巧玲珑<a href="http://pan.baidu.com/s/1i3zG0L3" target="_blank">百度网盘下载</a>   </p>
<ol>
<li>minimal版的CentOS网络默认没有打开<br>用以下命令打开：<br><code>ifconfig eth0 up</code><br><code>dhclient eth0</code><br>可以修改<em>/etc/sysconfig/network-scripts/ifcfg-eth0</em>将<em>ONBOOT=no</em> 改成<em>ONBOOT=yes</em>开机打开网络</li>
</ol>
<p>为方便之后的操作，可能还需要以下操作…..<br><code>yum update</code> 先更新一下会自动选最快的源<br>常用软件安装<br><code>yum install vim wget</code><br>下面这些你可能会能也会用到<br><code>yum install lsof make ntp tcpdump time  zip unzip git</code>    </p>
</blockquote>
</blockquote>
<p><strong>注意：</strong></p>
<ul>
<li>/etc/sysconfig/network中HOSTNAME的值初始值是安装的时候提供的主机名，而在/etc/hosts中又没有提供相应的映射，Hadoop各组件之件默认会用HOSTNAE+端口号进行通信，所以默认情况下会出错，并且我们需要的是宿主机中进行开发测试，也就是需要外部访问此伪分布式集群，所以你需要在/etc/hosts文件中加入一条映射：</li>
</ul>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
</pre></td><td class="code"><pre><span class="number">192.168</span><span class="number">.242</span><span class="number">.129</span>   centos<span class="preprocessor">.migle</span>
</pre></td></tr></table></figure>


<blockquote>
<blockquote>
<p>以上需要按实际情况做修改<strong>192.168.242.129</strong>是文中虚拟机地址， <strong>centos.migle</strong>是文中虚拟机HOSTNAME，下文中不再特别说明，如有出现请按自已实际对应做修改  </p>
<p><em>估计不用虚拟机IP和HOSTNAME做映射也是可以，但需要把HOSTNAME映射成127.0.0.1，用一个新名字映射虚拟机IP也是可以的，但需要加两条!！</em></p>
</blockquote>
</blockquote>
<ul>
<li>CentOS默认iptables是开的，可以这样查看状态<code>service iptables status</code> 而本文描述的是在虚拟机中安装的Hadoop，会在宿主机中通过WEB UI或客户端的形式访问虚拟机中的Hadoop所以为方便起见把Iptables给关了：<code>service stop iptables</code> 可以直接设成开机不启动<code>chkconfig iptables off</code>免得麻烦 </li>
</ul>
<h3 id="软件环境">软件环境</h3>
<ol>
<li><p>JDK安装<br>先检查是否已经安装<code>java  -version</code>环境变量是否已经设置<code>echo $JAVA_HOME</code> 如果没安装继续看下面，如果都没问题进入<br><a href="#ssh_install">下一步</a> </p>
<ol>
<li>下载    ：<a href="http://www.oracle.com/technetwork/java/javase/downloads/jdk7-downloads-1880260.html" target="_blank">http://www.oracle.com/technetwork/java/javase/downloads/jdk7-downloads-1880260.html</a></li>
<li><p>安装：rpm -i jdk-7u55-linux-x64.rpm</p>
</li>
<li><p>环境变量设置：<strong>/etc/profile</strong>  添加以下内容:</p>
</li>
</ol>
</li>
</ol>
<figure class="highlight export"><figcaption><span>JAVA_HOME=/usr/java/jdk1.7.0_55    </span></figcaption><table><tr><td class="gutter"><pre>1
2
</pre></td><td class="code"><pre><span class="keyword">export</span> CLASSPATH=.:<span class="variable">$JAVA_HOME</span>/lib/dt.jar:<span class="variable">$JAVA_HOME</span>/lib/tools.jar      
<span class="keyword">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$JAVA_HOME</span>/bin
</pre></td></tr></table></figure>


<pre><code>&gt;&gt; *重新登录或  <span class="escape">`s</span>ource /etc/profile<span class="escape">` </span>生效* 
</code></pre><ol>
<li><a name="ssh_install">ssh  server</a>  </li>
</ol>
<p>伪分布式运行应该是不需要SSH Server的，安装主要是为方便在宿主机中用XShell连接虚拟机，不过好处是CentOS自带,不用额外安装</p>
<h2 id="Hadoop">Hadoop</h2>
<h3 id="安装">安装</h3>
<ol>
<li>设置软件源  </li>
</ol>
<figure class="highlight wget"><figcaption><span>http://archive.cloudera.com/cdh5/one-click-install/redhat/6/x86_64/cloudera-cdh-5-0.x86_64.rpm</span></figcaption><table><tr><td class="gutter"><pre>1
2
</pre></td><td class="code"><pre>sudo yum --nogpgcheck localinstall cloudera-cdh-<span class="number">5</span>-<span class="number">0.</span>x86_64<span class="preprocessor">.rpm</span>  
sudo rpm --import http://archive<span class="preprocessor">.cloudera</span><span class="preprocessor">.com</span>/cdh5/redhat/<span class="number">6</span>/x86_64/cdh/RPM-GPG-KEY-cloudera
</pre></td></tr></table></figure>


<ol>
<li>安装:<br> <code>sudo yum install hadoop-conf-pseudo</code></li>
<li>检查安装：<br> <code>rpm -ql hadoop-conf-pseudo</code><br> <code>hadoop version</code></li>
</ol>
<h3 id="配置">配置</h3>
<blockquote>
<blockquote>
<p>CDH5把Hadoop的配置文件都是在/etc/hadoop/conf下面放着伪分布部署时会有一个名为conf.pseudo的符号链接如果你需要在宿主机中访问，默认配置不用改变<br>CDH5的Hadoop部署只需要修改<strong>core-site.xml</strong>一个文件的一个位置，如果你不需要在虚拟机外部分访问，可以不用修改  </p>
</blockquote>
</blockquote>
<ul>
<li>修改：<strong>core-site.xml</strong>    </li>
</ul>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
4
5
</pre></td><td class="code"><pre>  <span class="tag">&lt;<span class="title">property</span>&gt;</span>
    <span class="tag">&lt;<span class="title">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="title">name</span>&gt;</span>
    <span class="comment">&lt;!--把localhost修改成VM的IP，本文中修改为：192.168.242.129，如果配置成VM的HOSTNAME，在VM上操作没问题，但宿主机用JAVA API操作的时候会报报错!!--&gt;</span>
    <span class="tag">&lt;<span class="title">value</span>&gt;</span>hdfs://localhost:8020<span class="tag">&lt;/<span class="title">value</span>&gt;</span>
  <span class="tag">&lt;/<span class="title">property</span>&gt;</span>
</pre></td></tr></table></figure>


<ul>
<li><p>格式化HDFS：<code>sudo -u hdfs hdfs namenode -format</code>  </p>
<blockquote>
<blockquote>
<p>可以看看： <em>/etc/hadoop/conf.pseudo/hdfs-site.xml</em><br>namenode的data分别保存在：<br><em>/var/lib/hadoop-hdfs/cache/hdfs/dfs/name</em><br><em>/var/lib/hadoop-hdfs/cache/hdfs/dfs/data</em>  </p>
</blockquote>
</blockquote>
</li>
<li><p>启动服务： for x in `cd /etc/init.d ; ls hadoop-hdfs-*` ; do sudo service $x start ; done</p>
<blockquote>
<blockquote>
<p>下次开机会自动启动</p>
</blockquote>
</blockquote>
</li>
<li><p>宿主机浏览器里打开：<a href="http://centos.migle:50070/" target="_blank">http://centos.migle:50070/</a> 如果看到类似以下界面，说明问题成功了一小步！.. </p>
<blockquote>
<blockquote>
<p>如果使用虚拟机的HOSTNAME则需要在宿主机的hosts文件中加入相应映射，否则请直接用IP地址<br><img src="/images/cdh5-50070.jpg" alt="psudo-50070"></p>
</blockquote>
</blockquote>
</li>
<li><p>创建相关目录</p>
</li>
</ul>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
4
5
</pre></td><td class="code"><pre>sudo <span class="attribute">-u</span> hdfs hadoop fs <span class="attribute">-mkdir</span> <span class="attribute">-p</span> /tmp/hadoop<span class="attribute">-yarn</span>/staging/history/done_intermediate
sudo <span class="attribute">-u</span> hdfs hadoop fs <span class="attribute">-chown</span> <span class="attribute">-R</span> mapred:mapred /tmp/hadoop<span class="attribute">-yarn</span>/staging 
sudo <span class="attribute">-u</span> hdfs hadoop fs <span class="attribute">-chmod</span> <span class="attribute">-R</span> <span class="number">1777</span> /tmp 
sudo <span class="attribute">-u</span> hdfs hadoop fs <span class="attribute">-mkdir</span> <span class="attribute">-p</span> /<span class="built_in">var</span>/<span class="keyword">log</span>/hadoop<span class="attribute">-yarn</span>
sudo <span class="attribute">-u</span> hdfs hadoop fs <span class="attribute">-chown</span> yarn:mapred /<span class="built_in">var</span>/<span class="keyword">log</span>/hadoop<span class="attribute">-yarn</span>
</pre></td></tr></table></figure>


<p>查看结果： <code>hadoop fs -ls -R /</code>   也可以在WEB界面中查看    </p>
<blockquote>
<blockquote>
<p>安装的时候会自动创建hadoop,hdfs,yarn,mapred等用户</p>
</blockquote>
</blockquote>
<p><em><code>hadoop fs</code> 会改给出HDFS的命令的帮助，和相应的Linux名字和相应功能都很像，参数也比较简单</em>  </p>
<ul>
<li>启动YARN服务  </li>
</ul>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
</pre></td><td class="code"><pre>sudo service hadoop<span class="attribute">-yarn</span><span class="attribute">-resourcemanager</span> start   
sudo service hadoop<span class="attribute">-yarn</span><span class="attribute">-nodemanager</span> start   
sudo service hadoop<span class="attribute">-mapreduce</span><span class="attribute">-historyserver</span> start
</pre></td></tr></table></figure>


<blockquote>
<blockquote>
<p>下次开机会自动启动</p>
</blockquote>
</blockquote>
<p><code>jps</code>后会有类似如下的输出:</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
</pre></td><td class="code"><pre>13988 SecondaryNameNode  
14627 ResourceManager  
15051 JobHistoryServer  
14705 NodeManager  
13878 NameNode  
13785 DataNode
</pre></td></tr></table></figure>


<p>如有以上输出，说明配置基本完成，进行下一步测试</p>
<h3 id="开发测试">开发测试</h3>
<h4 id="本地MR任务测试">本地MR任务测试</h4>
<p>为管理方便给root用户在HDFS上创建个目录，并赋权   </p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
</pre></td><td class="code"><pre>sudo <span class="attribute">-u</span> hdfs hadoop fs <span class="attribute">-mkdir</span> <span class="attribute">-p</span> /user/root
sudo <span class="attribute">-u</span> hdfs hadoop fs <span class="attribute">-chown</span> root /user/root
</pre></td></tr></table></figure>


<p>在<strong>/etc/profile</strong> 中添加个环境变量<br>export HADOOP_MAPRED_HOME=/usr/lib/hadoop-mapreduce<br>export CLASSPATH=$CLASSPATH:$HADOOP_MAPRED_HOME</p>
<blockquote>
<blockquote>
<p>hadoop的JAR都在HADOOP_MAPRED_HOME目录下,但不知道这个环境变量是用来干什么的</p>
</blockquote>
</blockquote>
<p>创建一个test.txt的文件加上几行内容</p>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
</pre></td><td class="code"><pre><span class="built_in">echo</span> <span class="string">"hello"</span> &gt;&gt; test.txt
<span class="built_in">echo</span> <span class="string">"hadoop"</span> &gt;&gt; test.txt
<span class="built_in">echo</span> <span class="string">"hi,hadoop"</span> &gt;&gt; test.txt
</pre></td></tr></table></figure>


<p>上传到hdfs中:<code>hadoop fs -put -f test.txt /user/root/</code><br>查看文件：<code>hadoop fs -ls -R  /user/root/</code><br>查看文件内容   <code>hadoop fs -cat  /user/root/test.txt</code><br>如下图：<br><img src="/images/cdh5-put-lsr-cat.jpg" alt="cdh5-put-lsr-cat"></p>
<p>运行一个自带MR例子，<br> hadoop jar /usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar wordcount test.txt  output </p>
<blockquote>
<blockquote>
<p>hadoop-mapreduce-examples.jar源码在Hadoop的源码包里有</p>
</blockquote>
</blockquote>
<p>结果会在output目录下生成output是相对路径，绝对</p>
<p>/user/root/output</p>
<p>查看结果：<br>hadoop fs -ls -R output<br>hadoop fs -cat /user/root/output/part-r-00000<br><img src="/images/cdh5-cat-output-1.png" alt="Alt text"></p>
<h4 id="远程HDFS_JAVA_API">远程HDFS JAVA API</h4>
<p>代码见：<a href="https://github.com/longforfreedom/StudyHadoop" target="_blank">https://github.com/longforfreedom/StudyHadoop</a></p>
<h2 id="HBASE">HBASE</h2>
<h3 id="安装：">安装：</h3>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
4
</pre></td><td class="code"><pre><span class="built_in">sudo</span> yum install zookeeper-server
<span class="built_in">sudo</span> yum install hbase-master
<span class="built_in">sudo</span> yum install hbase
<span class="built_in">sudo</span> yum install hbase-regionserver
</pre></td></tr></table></figure>


<p>可选：<br><code>sudo yum install hbase-thrift</code>  ##thrift接口需要<br><code>sudo yum install hbase-rest</code>    ##rest接口  </p>
<blockquote>
<blockquote>
<p>查看：<code>rpm -ql hbase</code></p>
</blockquote>
</blockquote>
<h3 id="配置-1">配置</h3>
<ol>
<li>创建相关目录<br>zookeeper的dataDir</li>
</ol>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
</pre></td><td class="code"><pre>mkdir <span class="attribute">-p</span> /<span class="built_in">var</span>/lib/zookeeper
chown <span class="attribute">-R</span> zookeeper /<span class="built_in">var</span>/lib/zookeeper<span class="subst">/</span>
</pre></td></tr></table></figure>


<p>hbase目录<em>ms会自动创建</em><br>sudo -u hdfs hadoop fs -mkdir /hbase<br>sudo -u hdfs hadoop fs -chown hbase /hbase</p>
<ol>
<li><p>配置：<br>两个配置文件 <strong>/etc/hadoop/conf/hdfs-site.xml</strong>和<strong>/etc/hbase/conf/hbase-site.xml</strong>  </p>
<ul>
<li><p><strong>/etc/hadoop/conf/hdfs-site.xml</strong>中添加<br><property><br><name>dfs.datanode.max.xcievers</name><br><value>4096</value><br></property></p>
<blockquote>
<blockquote>
<p>单机小测试不改这个应该不会出错!!<br><strong>修改hdfs-site.xml需要重启Hadoop</strong>  </p>
</blockquote>
</blockquote>
</li>
<li><p><strong>/etc/hbase/conf/hbase-site.xml</strong> 添加以下： </p>
</li>
</ul>
</li>
</ol>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</pre></td><td class="code"><pre><span class="tag">&lt;<span class="title">property</span>&gt;</span>
<span class="tag">&lt;<span class="title">name</span>&gt;</span>hbase.cluster.distributed<span class="tag">&lt;/<span class="title">name</span>&gt;</span>
<span class="tag">&lt;<span class="title">value</span>&gt;</span>true<span class="tag">&lt;/<span class="title">value</span>&gt;</span>
<span class="tag">&lt;/<span class="title">property</span>&gt;</span>

<span class="tag">&lt;<span class="title">property</span>&gt;</span>
<span class="tag">&lt;<span class="title">name</span>&gt;</span>hbase.rootdir<span class="tag">&lt;/<span class="title">name</span>&gt;</span>
<span class="comment">&lt;!--按实际情况修改--&gt;</span>
<span class="tag">&lt;<span class="title">value</span>&gt;</span>hdfs://centos.migle:8020/hbase<span class="tag">&lt;/<span class="title">value</span>&gt;</span>
<span class="tag">&lt;/<span class="title">property</span>&gt;</span>

<span class="tag">&lt;<span class="title">property</span>&gt;</span> 
<span class="tag">&lt;<span class="title">name</span>&gt;</span>hbase.zookeeper.quorum<span class="tag">&lt;/<span class="title">name</span>&gt;</span>      
<span class="tag">&lt;<span class="title">value</span>&gt;</span>centos.migle<span class="tag">&lt;/<span class="title">value</span>&gt;</span>    
<span class="tag">&lt;/<span class="title">property</span>&gt;</span>
</pre></td></tr></table></figure>


<ol>
<li><p>启动：</p>
<ul>
<li>启动Zookeeper<br>  <code>sudo service zookeeper-server init</code> #第一次启动时执行以后再不需要<br>  <code>sudo service zookeeper-server start</code><blockquote>
<blockquote>
<p>测试zookeeper:<code>zookeeper-client -server localhost:2181</code></p>
</blockquote>
</blockquote>
</li>
<li>启动Hbase<br>  <code>sudo service hbase-master start</code><br>  <code>sudo service hbase-regionserver start</code>  </li>
</ul>
</li>
</ol>
<blockquote>
<blockquote>
<p>下次开机会自动启动</p>
<p>宿主机中的访问：<a href="http://centos.migle:60010/" target="_blank">http://centos.migle:60010/</a><br><img src="/images/cdh5-60010.jpg" alt="cdh5-60010">  </p>
</blockquote>
</blockquote>
<h3 id="开发测试-1">开发测试</h3>
<h4 id="HBASE_SHELL_基本操作">HBASE SHELL 基本操作</h4>
<p><code>hbase shell</code> 进入HBASE SHELL,提示符会变成类似:<strong>hbase(main):002:0&gt;</strong>以下命令都在HBASE SHELL执行. </p>
<ul>
<li>查看状态 :<code>status</code>  </li>
<li>查看版本:<code>version</code>  </li>
<li>创建表：<code>create &#39;mtable&#39;,&#39;cf&#39;</code>  指定表名和列族,多个列族用“,”分隔如：<code>create &#39;mtable&#39;,&#39;cf&#39;,&#39;cf2&#39;</code>  </li>
<li>插入数据: <code>put &#39;表名&#39;,&#39;rowKey&#39;,&#39;列名&#39;,&#39;列值&#39;</code><br>  <code>put &#39;mtable&#39;,&#39;rowKey1&#39;,&#39;cf:acc_nbr&#39;,&#39;18797384480&#39;</code><br>   <code>put &#39;mtable&#39;,&#39;rowKey1&#39;,&#39;cf:name&#39;,&#39;migle&#39;</code><br>列可以动态创建:  列格式是:<em>列族:列名</em>  </li>
<li>查看数据:<br>  <strong>单行:</strong>get ‘mtable’ , ‘rowKey1’<br>   get ‘mtable’,’rowKey1’,’cf:acc_nbr’<br>   get ‘mtable’,’rowKey1’,’cf’<br>  <strong>所有:</strong>scan ‘mtable’    </li>
<li>行数：<code>count &#39;mtable&#39;</code>  </li>
<li>更新数据：<code>put &#39;mtable&#39;,&#39;1&#39;,&#39;cf:acc_nbr&#39;,&#39;18797384481&#39;</code></li>
<li>删除数据：<code>delete &#39;mtable&#39;,&#39;1&#39;,&#39;cf:name&#39;</code>  </li>
<li>清空表： <code>truncate &#39;mtable&#39;</code>  </li>
<li>查看表结构：<code>describe &#39;mtable&#39;</code>  </li>
<li>修改表结构: <ol>
<li>添加一个列族：</li>
</ol>
</li>
</ul>
<figure class="highlight disable"><figcaption><span>'mtable'  </span></figcaption><table><tr><td class="gutter"><pre>1
2
</pre></td><td class="code"><pre>   alter <span class="string">'mtable'</span>, NAME =&gt; <span class="string">'cf2'</span>  
   enable <span class="string">'mtable'</span>
</pre></td></tr></table></figure>


<pre><code><span class="bullet">2. </span>删除列族： 
</code></pre><figure class="highlight disable"><figcaption><span>'mtable'   </span></figcaption><table><tr><td class="gutter"><pre>1
2
</pre></td><td class="code"><pre>alter <span class="string">'mtable'</span>, <span class="string">'delete'</span> =&gt; <span class="string">'cf2'</span>  
enable <span class="string">'mtable'</span>
</pre></td></tr></table></figure>


<ul>
<li>删除表：</li>
</ul>
<figure class="highlight"><table><tr><td class="gutter"><pre>1
2
</pre></td><td class="code"><pre>disable <span class="string">'mtable'</span>
<span class="keyword">drop</span> <span class="string">'mtable'</span>
</pre></td></tr></table></figure>


<h4 id="JAVA_API远程测试">JAVA API远程测试</h4>
<p>代码见：<a href="https://github.com/longforfreedom/StudyHadoop" target="_blank">https://github.com/longforfreedom/StudyHadoop</a></p>
<h4 id="Python">Python</h4>
<hr>
<p>@TODO</p>
<blockquote>
<blockquote>
<p>安装 thrift<br>thrift依赖<br>sudo yum install automake libtool flex bison pkgconfig gcc-c++ boost-devel libevent-devel zlib-devel python-devel ruby—-devel<br>/usr/lib/hbase/include/thrift<br><a href="http://blog.csdn.net/guxch/article/details/12163047" target="_blank">http://blog.csdn.net/guxch/article/details/12163047</a></p>
</blockquote>
</blockquote>
<h2 id="其它:">其它:</h2>
<ol>
<li>在虚拟机中不要把HOSTNAME映射成127.0.0.1否则宿主机中JAVA API不能访问HBASE！！</li>
<li>可以pom.xml中加入cloudera的仓库，但直接用Apache版本的好像也没问题</li>
</ol>
<figure class="highlight <repositories>"><table><tr><td class="gutter"><pre>1
2
3
4
5
</pre></td><td class="code"><pre>    <span class="tag">&lt;<span class="title">repository</span>&gt;</span>
      <span class="tag">&lt;<span class="title">id</span>&gt;</span>cloudera<span class="tag">&lt;/<span class="title">id</span>&gt;</span>
      <span class="tag">&lt;<span class="title">url</span>&gt;</span>https://repository.cloudera.com/artifactory/cloudera-repos/<span class="tag">&lt;/<span class="title">url</span>&gt;</span>
    <span class="tag">&lt;/<span class="title">repository</span>&gt;</span>
  <span class="tag">&lt;/<span class="title">repositories</span>&gt;</span>
</pre></td></tr></table></figure>


<h2 id="参考资料">参考资料</h2>
<ul>
<li><p><a href="http://www.cloudera.com/content/cloudera-content/cloudera-docs/CDH5/latest/CDH5-Quick-Start/cdh5qs_cdh5_pseudo.html" target="_blank">Installing CDH 5 on a Single Linux Node in Pseudo-distributed Mode</a>  </p>
</li>
<li><p><a href="http://www.cloudera.com/content/cloudera-content/cloudera-docs/CDH5/latest/CDH5-Requirements-and-Supported-Versions/CDH5-Requirements-and-Supported-Versions.html" target="_blank">CDH 5 Requirements and Supported Versions</a></p>
</li>
<li><p><a href="http://www.cloudera.com/content/cloudera-content/cloudera-docs/CDH5/latest/CDH5-Installation-Guide/cdh5ig_hbase_pseudo_configure.html" target="_blank">Configuring HBase in Pseudo-Distributed Mode</a></p>
</li>
<li><p><a href="http://blog.csdn.net/shirdrn/article/details/6562292" target="_blank">http://blog.csdn.net/shirdrn/article/details/6562292</a>  </p>
</li>
</ul>
]]></content>
    
    
      <category term="Hadoop" scheme="http://www.migle.me/tags/Hadoop/"/>
    
      <category term="CDH5" scheme="http://www.migle.me/tags/CDH5/"/>
    
      <category term="HBase" scheme="http://www.migle.me/tags/HBase/"/>
    
      <category term="Hadoop" scheme="http://www.migle.me/categories/Hadoop/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[HBase入门笔记]]></title>
    <link href="http://www.migle.me/post/hbase%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0/"/>
    <id>http://www.migle.me/post/hbase入门笔记/</id>
    <published>2014-04-10T03:28:47.000Z</published>
    <updated>2014-05-13T02:29:00.000Z</updated>
    <content type="html"><![CDATA[<h2 id="安装配置">安装配置</h2>
<ul>
<li>条件：Hadoop集群已搭建</li>
<li>下载  …………………</li>
<li>安装：<code>tar zxvf hbase-0.98.1-hadoop2-bin.tar.gz</code>  </li>
<li>集群模式配置：<br>  单机模式和伪分布式请参见官方文档，集群模式请先保证你已经配置好Hadoop集群<br>  在<em>conf/hbase-site.xml</em>中添加以下：</li>
</ul>
<figure class="highlight <configuration>"><table><tr><td class="gutter"><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
</pre></td><td class="code"><pre><span class="tag">&lt;<span class="title">property</span>&gt;</span>
    	<span class="tag">&lt;<span class="title">name</span>&gt;</span>hbase.zookeeper.quorum<span class="tag">&lt;/<span class="title">name</span>&gt;</span>
    	<span class="tag">&lt;<span class="title">value</span>&gt;</span>avgopt2,avgwebt1,avgweb2<span class="tag">&lt;/<span class="title">value</span>&gt;</span>
    	<span class="tag">&lt;<span class="title">description</span>&gt;</span>The directory shared by RegionServers.
    	<span class="tag">&lt;/<span class="title">description</span>&gt;</span>
  		<span class="tag">&lt;/<span class="title">property</span>&gt;</span>
  	<span class="tag">&lt;<span class="title">property</span>&gt;</span>
    	<span class="tag">&lt;<span class="title">name</span>&gt;</span>hbase.zookeeper.property.dataDir<span class="tag">&lt;/<span class="title">name</span>&gt;</span>
    	<span class="comment">&lt;!--注意这个值在169上要改成/vgopbak/hadoop2/zookeeper--&gt;</span>
    	<span class="tag">&lt;<span class="title">value</span>&gt;</span>/vgopbak/hadoop/zookeeper<span class="tag">&lt;/<span class="title">value</span>&gt;</span>
    	<span class="tag">&lt;<span class="title">description</span>&gt;</span>Property from ZooKeeper's config zoo.cfg.
    	The directory where the snapshot is stored.
    	<span class="tag">&lt;/<span class="title">description</span>&gt;</span>
  	<span class="tag">&lt;/<span class="title">property</span>&gt;</span>

<span class="tag">&lt;<span class="title">property</span>&gt;</span>
	<span class="tag">&lt;<span class="title">name</span>&gt;</span>hbase.rootdir<span class="tag">&lt;/<span class="title">name</span>&gt;</span>
	<span class="tag">&lt;<span class="title">value</span>&gt;</span>hdfs://135.191.27.175:9999/hbase<span class="tag">&lt;/<span class="title">value</span>&gt;</span>
	<span class="tag">&lt;<span class="title">description</span>&gt;</span>The directory shared by RegionServers.
	<span class="tag">&lt;/<span class="title">description</span>&gt;</span>
<span class="tag">&lt;/<span class="title">property</span>&gt;</span>

<span class="tag">&lt;<span class="title">property</span>&gt;</span>
	<span class="tag">&lt;<span class="title">name</span>&gt;</span>hbase.cluster.distributed<span class="tag">&lt;/<span class="title">name</span>&gt;</span>
	<span class="tag">&lt;<span class="title">value</span>&gt;</span>true<span class="tag">&lt;/<span class="title">value</span>&gt;</span>
	<span class="tag">&lt;<span class="title">description</span>&gt;</span>The mode the cluster will be in. Possible values are
        	false: standalone and pseudo-distributed setups with managed Zookeeper
		true: fully-distributed with unmanaged Zookeeper Quorum (see hbase-env.sh)
        <span class="tag">&lt;/<span class="title">description</span>&gt;</span>
    <span class="tag">&lt;/<span class="title">property</span>&gt;</span>

<span class="comment">&lt;!--这个端口默认是60000，但已被占用--&gt;</span>
<span class="tag">&lt;<span class="title">property</span>&gt;</span>
	<span class="tag">&lt;<span class="title">name</span>&gt;</span>hbase.master.port<span class="tag">&lt;/<span class="title">name</span>&gt;</span>
	<span class="tag">&lt;<span class="title">value</span>&gt;</span>40001<span class="tag">&lt;/<span class="title">value</span>&gt;</span>
<span class="tag">&lt;/<span class="title">property</span>&gt;</span>
<span class="tag">&lt;/<span class="title">configuration</span>&gt;</span>
</pre></td></tr></table></figure>


<p>在<em>conf/regionservers</em>中添加:  </p>
<figure class="highlight 135.191.27.156"><table><tr><td class="gutter"><pre>1
2
</pre></td><td class="code"><pre>135.191.27.161  
135.191.27.176
</pre></td></tr></table></figure>


<blockquote>
<blockquote>
<p>135.191.27.175是Hadoop的Master，NameNode也在上面    </p>
</blockquote>
</blockquote>
<p>复制到其它结点：  </p>
<p><code>scp -r hbase-0.98.1-hadoop2  135.191.27.161:/opt/hadoop/</code><br><code>scp -r hbase-0.98.1-hadoop2  135.191.27.176:/opt/hadoop/</code><br><code>scp -r hbase-0.98.1-hadoop2  135.191.27.156:/opt/hadoop/</code>    </p>
<p>启动HBASE<br><code>./bin/start-hbase.sh</code>   </p>
<p>启动HBASE SHELL<br><code>./bin/hbase shell</code>  </p>
<p><strong>文件打开限制修改</strong><br><strong>HDFS配置修改</strong></p>
<p>jps<br>175上会有：HMaster进程<br>其它机器上会有HRegionServer和HQuorumPeer进程</p>
<p>HMaster Web界面<br><a href="http://135.191.27.175:60010/" target="_blank">http://135.191.27.175:60010/</a></p>
<h2 id="测试">测试</h2>
<p>从VGOP的库上导一个用户基本信息表出来<br>db2 “export to gdi_mbuser_baseinfo_20140424.dat of del select bigint(mbuser_id),cust_name,area_id from nmk.gdi_mbuser_baseinfo_20140424 with ur”</p>
<p>-put 到HDFS<br>gdi_mbuser_baseinfo_20140424.dat</p>
<p>创建表：</p>
<blockquote>
<blockquote>
<p>create ‘gdi_mbuser_20140424’,’pro’<br>create ‘gdi_mbuser_20140424’, {NAME =&gt; ‘pro’},   {SPLITS =&gt; [‘g’, ‘m’, ‘r’, ‘w’]}<br>bin/hbase org.apache.hadoop.hbase.mapreduce.ImportTsv -Dimporttsv.separator=”,” -Dimporttsv.columns=HBASE_ROW_KEY, baseinfo:cust_name, baseinfo:area_id, gdi_mbuser_20140424 /qhbi/gdi_mbuser_baseinfo_20140424.dat</p>
</blockquote>
</blockquote>
<h2 id="HBASE_SHELL_基本操作">HBASE SHELL 基本操作</h2>
<p><code>hbase shell</code> 进入HBASE SHELL,提示符会变成类似:<strong>hbase(main):002:0&gt;</strong>以下命令都在HBASE SHELL执行. </p>
<ul>
<li>查看状态 :<code>status</code>  </li>
<li>查看版本:<code>version</code>  </li>
<li>创建表：<code>create &#39;mtable&#39;,&#39;cf&#39;</code>  指定表名和列族,多个列族用“,”分隔如：<code>create &#39;mtable&#39;,&#39;cf&#39;,&#39;cf2&#39;</code>  </li>
<li>插入数据: <code>put &#39;表名&#39;,&#39;rowKey&#39;,&#39;列名&#39;,&#39;列值&#39;</code><br>  <code>put &#39;mtable&#39;,&#39;rowKey1&#39;,&#39;cf:acc_nbr&#39;,&#39;18797384480&#39;</code><br>   <code>put &#39;mtable&#39;,&#39;rowKey1&#39;,&#39;cf:name&#39;,&#39;migle&#39;</code><br>列可以动态创建:  列格式是:<em>列族:列名</em>  </li>
<li>查看数据:<br>  <strong>单行:</strong>get ‘mtable’ , ‘rowKey1’<br>   get ‘mtable’,’rowKey1’,’cf:acc_nbr’<br>   get ‘mtable’,’rowKey1’,’cf’<br>  <strong>所有:</strong>scan ‘mtable’    </li>
<li>行数：<code>count &#39;mtable&#39;</code>  </li>
<li>更新数据：<code>put &#39;mtable&#39;,&#39;1&#39;,&#39;cf:acc_nbr&#39;,&#39;18797384481&#39;</code></li>
<li>删除数据：<code>delete &#39;mtable&#39;,&#39;1&#39;,&#39;cf:name&#39;</code>  </li>
<li>清空表： <code>truncate &#39;mtable&#39;</code>  </li>
<li>查看表结构：<code>describe &#39;mtable&#39;</code>  </li>
<li>修改表结构: <ol>
<li>添加一个列族：</li>
</ol>
</li>
</ul>
<figure class="highlight disable"><figcaption><span>'mtable'  </span></figcaption><table><tr><td class="gutter"><pre>1
2
</pre></td><td class="code"><pre>   alter <span class="string">'mtable'</span>, NAME =&gt; <span class="string">'cf2'</span>  
   enable <span class="string">'mtable'</span>
</pre></td></tr></table></figure>


<pre><code><span class="bullet">2. </span>删除列族： 
</code></pre><figure class="highlight disable"><figcaption><span>'mtable'   </span></figcaption><table><tr><td class="gutter"><pre>1
2
</pre></td><td class="code"><pre>alter <span class="string">'mtable'</span>, <span class="string">'delete'</span> =&gt; <span class="string">'cf2'</span>  
enable <span class="string">'mtable'</span>
</pre></td></tr></table></figure>


<ul>
<li>删除表：</li>
</ul>
<figure class="highlight disable"><figcaption><span>'mtable'</span></figcaption><table><tr><td class="gutter"><pre>1
</pre></td><td class="code"><pre><span class="keyword">drop</span> <span class="string">'mtable'</span>
</pre></td></tr></table></figure>


<h2 id="程序开发">程序开发</h2>
<h3 id="JAVA_API">JAVA API</h3>
]]></content>
    
    
      <category term="Hadoop" scheme="http://www.migle.me/tags/Hadoop/"/>
    
      <category term="HBase" scheme="http://www.migle.me/tags/HBase/"/>
    
      <category term="Hadoop" scheme="http://www.migle.me/categories/Hadoop/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[hadoop环境搭建笔记]]></title>
    <link href="http://www.migle.me/post/hadoop%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E7%AC%94%E8%AE%B0/"/>
    <id>http://www.migle.me/post/hadoop环境搭建笔记/</id>
    <published>2014-04-02T06:57:34.000Z</published>
    <updated>2014-05-13T02:29:09.000Z</updated>
    <content type="html"><![CDATA[<h1 id="环境">环境</h1>
<h2 id="硬件环境：">硬件环境：</h2>
<p>  共有如下四台机器,网络互通</p>
<ol>
<li>135.191.27.175  </li>
<li>135.191.27.176  </li>
<li>135.191.27.161 </li>
<li>135.191.27.156   </li>
</ol>
<p>175为NameNode，其余三台机器为DataNode  </p>
<blockquote>
<blockquote>
<p><em>为行文方便,涉及到相关机器IP的时候只写最后一个IP段</em> </p>
</blockquote>
</blockquote>
<h2 id="软件环境：">软件环境：</h2>
<ol>
<li>操作系统: Linux</li>
<li>必备软件: ssh/ Oracle JDK1.6</li>
</ol>
<blockquote>
<blockquote>
<p>SSH一般发行版都自带了，JDK大多数系统带的都是Open JDK  </p>
</blockquote>
</blockquote>
<ol>
<li><p>用户创建各机器上分别执行<br> 创建HADOOP用户组<code>groupadd hadoop</code><br> 创建用户：<code>adduser hadoop -g hadoop --password ha_12QW</code></p>
</li>
<li><p>SSH免密码登陆配置<br> 用新hadoop账号登录<br> 生成密钥： ssh-keygen -t rsa<br> 在175上合并：<br> scp hadoop@135.191.27.156:/home/hadoop/.ssh/id_rsa.pub ./a.pub<br> scp hadoop@135.191.27.161:/home/hadoop/.ssh/id_rsa.pub ./b.pub<br> scp hadoop@135.191.27.176:/home/hadoop/.ssh/id_rsa.pub ./c.pub<br> cat id_rsa.pub &gt;&gt; authorized_keys<br> cat ./a.pub &gt;&gt; authorized_keys<br> cat ./b.pub &gt;&gt; authorized_keys<br> cat ./c.pub &gt;&gt; authorized_keys</p>
</li>
</ol>
<p>复制到其它机器上</p>
<p>scp authorized_keys  135.191.27.176:/home/hadoop/.ssh/<br>scp authorized_keys  135.191.27.161:/home/hadoop/.ssh/<br>scp authorized_keys  135.191.27.156:/home/hadoop/.ssh/ </p>
<p><strong>有可能这需要修改一相以下两个文件的权限：</strong><br>chmod 700 /home/hadoop/.ssh/<br>chmod 600 /home/hadoop/.ssh/authorized_keys</p>
<p>测试：<br>    各个机器都交互测试一下<br>    ssh 135.191.27.156  不要密码直接登陆，证明配置成功</p>
<ol>
<li><p>host配置<br> 用ROOT在一台机器上设置好，然后scp到其它机器 </p>
</li>
<li><p>Hadoop配置<br> 所有机器上：<br> mkdir /opt/hadoop<br> chown -R hadoop:hadoop /opt/hadoop/<br> mkdir /vgopbak/hadoop<br> chown -R hadoop:hadoop /vgopbak/hadoop </p>
</li>
</ol>
<p>用hadoop用户做以下操作：<br>mkdir /vgopbak/hadoop/namedir </p>
<p>其它机器：<br>mkdir /vgopbak/hadoop/datadir   </p>
<p> <strong>175和176共的/vgopbak上当是共享存储，所以在176上创建为/vgopbak/hadoop2/，否则目录权限会有问题</strong> </p>
<p>在175上配置好，复制到其它机器<br><strong>conf/core-site.xml</strong></p>
<configuration><br><property><br>        <name>fs.defaultFS</name><br>        <value>hdfs://135.191.27.175:9999</value><br></property><br></configuration>


<p><strong>conf/hdfs-site.xml</strong></p>
<configuration><br><!--NameNode--><br><property><br>        <name>dfs.namenode.name.dir</name><br>        <value>/vgopbak/hadoop/namedir</value><br></property><br><!--DataNode--><br><br><!--在176上，这个值应该改成/vgopbak/hadoop2/datadir--><br><property><br>        <name>dfs.datanode.data.dir</name><br>        <value>/vgopbak/hadoop/datadir</value><br></property><br><br></configuration>


<p><strong>conf/yarn-site.xml</strong></p>
<configuration><br><br><!-- Site specific YARN configuration properties --><br><property><br>        <name>yarn.resourcemanager.address</name><br>        <value>135.191.27.175:8032</value><br></property><br><property><br>        <name>yarn.resourcemanager.scheduler.address</name><br>        <value>135.191.27.175:8030</value><br></property><br><br><property><br>        <name>yarn.resourcemanager.resource-tracker.address</name><br>        <value>135.191.27.175:8031</value><br></property><br><br><property><br>        <name>yarn.resourcemanager.admin.address</name><br>        <value>135.191.27.175:8033</value><br></property><br><br><property><br>        <name>yarn.resourcemanager.webapp.address</name><br>        <value>135.191.27.175:8088</value><br></property><br></configuration>


<p><strong>conf/mapred-site.xml</strong><br>暂不添加</p>
<p><strong>conf/slaves</strong><br>35.191.27.156<br>135.191.27.161<br>135.191.27.176</p>
<p>分发至其它节点<br>scp -r hadoop-2.2.0   135.191.27.161:/opt/hadoop/<br>scp -r hadoop-2.2.0   135.191.27.176:/opt/hadoop/<br>scp -r hadoop-2.2.0   135.191.27.156:/opt/hadoop/</p>
<h2 id="启动">启动</h2>
<p>格式化：bin/hdfs namenode -format</p>
<blockquote>
<blockquote>
<p>格式化成功后在/vgopbak/hadoop/namedir下面会有文件生成</p>
</blockquote>
</blockquote>
<p>启动：<br>sbin/start-dfs.sh<br>sbin/start-yarn.sh </p>
<p>可以用jps命令查看下，如果没东西，就需要看日志分析原因了</p>
<p><a href="http://135.191.27.175:8088" target="_blank">http://135.191.27.175:8088</a><br><a href="http://135.191.27.175:50070" target="_blank">http://135.191.27.175:50070</a></p>
<h2 id="测试">测试</h2>
<p>以下可以集群某一台机器上执行，也可以在客户端上执行</p>
<p>创建目录：</p>
<p>bin/hadoop fs -mkdir /qhbi</p>
<p>从DB2导出来些数据<br>db2 “export to gprs_ticket_20140420.dat of del select bigint(timeid),bigint(serv_id),bigint(DURATION), bigint(DATA_UP1), bigint(DATA_DOWN1), bigint(DURATION1),recordextension_new,bill_item from nwh.gprs_ticket_20140420 with ur”</p>
<p>put到HDFS中</p>
<p>bin/hadoop fs -put /vgopbak/gprs_ticket_20140420.dat   /qhbi</p>
<p>写代码，打包，<br>略</p>
<p>求时长<br>bin/hadoop jar StudyHadoop-1.0.jar  me.migle.mr.SumGPRSDuration /qhbi/gprs_ticket_20140420.dat  /qhbi/output_sum/<br>在<a href="http://135.191.27.175:50070中查看结果，" target="_blank">http://135.191.27.175:50070中查看结果，</a><br>导到结果输出目录上查看结果</p>
<p>拆分<br>bin/hadoop jar StudyHadoop-1.0.jar me.migle.mr.SplitBillItem /qhbi/gprs_ticket_20140420.dat   /qhbi/output_gprs/spliit/<br>在文件系统中查看结果</p>
<h2 id="其它">其它</h2>
<p>为方便起见可以将HADOOP的bin/ sbin/目录加入PATH</p>
]]></content>
    
    
      <category term="Hadoop" scheme="http://www.migle.me/tags/Hadoop/"/>
    
      <category term="Hadoop" scheme="http://www.migle.me/categories/Hadoop/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[git常用命令]]></title>
    <link href="http://www.migle.me/post/git%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"/>
    <id>http://www.migle.me/post/git常用命令/</id>
    <published>2014-01-12T06:55:07.000Z</published>
    <updated>2014-05-13T02:29:13.000Z</updated>
    <content type="html"><![CDATA[<h1 id="git常用命令">git常用命令</h1>
<h2 id="配置">配置</h2>
<p><code>git config -l</code>  #列举所有配置<br><code>git config --get user.name</code> #查看单个参数<br><code>git config --global user.name &quot;migle&quot;</code><br><code>git config --global user.email &quot;longforfreedom+github@gmail.com&quot;</code><br><code>git config --global core.quotepath false</code> #要不中文文件名都是数据编码,ore.quotepath设为false的话，就不会对0×80以上的字符进行quote。中文显示正常 。   </p>
<p><strong>别名</strong><br><code>git config --global alias.co checkout</code><br><code>git config --global alias.ci commit</code><br><code>git config --global alias.st status</code><br><code>git config --global alias.br branch</code>    </p>
<h2 id="远程">远程</h2>
<p><em>可以是本机的其它目录，或git、ssh、https等协议</em><br>检出仓库：<code>git clone git://github.com/jquery/jquery.git</code><br>查看远程仓库：<code>git remote -v</code><br>查看远程服务器仓库状态:<code>git remote show origin</code><br>添加远程仓库：<code>git remote add [name] [url]</code><br>删除远程仓库：<code>git remote rm [name]</code><br>修改远程仓库地址：<code>git remote set-url --push[name][newUrl]</code><br>git remote set-url origin  <a href="https://longforfreedom@github.com/longforfreedom/m-note.git" target="_blank">https://longforfreedom@github.com/longforfreedom/m-note.git</a><br>拉取远程仓库：<code>git pull [remoteName] [localBranchName]</code><br>推送远程仓库：<code>git push [remoteName] [localBranchName]</code>  </p>
<blockquote>
<blockquote>
<p><code>git pull  url</code>   #它从远程分支(remote branch)抓取修改的内容，然后把它合并进当前的分支，不同的仓库也能合并，确实不错</p>
</blockquote>
</blockquote>
<p><code>git remote add origin https://github.com/longforfreedom/m-note.git</code>         # 添加远程仓库地址，相当于一个别名<br>执行git fetch origin 的时候只抓取不合并，会有一个origin/master分支生成然后，再merge      </p>
<p><code>git remote set-url origin https://github.com/miadaner/miadaner.git</code> # 设置远程仓库地址(用于修改远程仓库地址)      </p>
<p><code>git push origin master</code>           #将本地主分支推到远程主分支<br><code>git push -u origin master</code>        #将本地主分支推到远程(如无远程主分支则创建，用于初始化远程仓库)  </p>
<h2 id="分支">分支</h2>
<p><code>git branch</code>   #列出当前本地所有分支<br><code>git branch -a</code> #列出当前本地及远程所有分支<br><code>git branch --no-merged</code> #查看没有合并的分支<br><code>git branch branhname</code>  #创建本地分支，直接使用<code>git push</code>时不会推送到远程<br><code>git checkout -b 分支名</code> #创建新分支并立即切换到新分支<br><code>git merge 分支名</code>  #合并到当前分支 ，如有冲突的话，会报错，需要手工处理完成后commit,再push远程<br><code>git push origin 分支名</code>   #推送本地分支到远程仓库<br><code>git push origin --delete 分支名</code> #删除远程分支<br><code>git branch -d branhname</code>  #删除本地分支，如果是没有合并的分支，用-D删除<br>“.git/HEAD”这个文件里保存的是我们当前在哪个分支上工作的信息。  </p>
<h2 id="diff">diff</h2>
<h2 id="合并">合并</h2>
<h2 id="回退">回退</h2>
<h2 id="其它">其它</h2>
<p>在Ubuntu13.10中bash可以自动补全git命令，但在CentOS6.4中发现不行，发现/etc/bash_completion.d/git 但是没有加载<br>试着执行一下 <code>source /etc/bash_completion.d/git</code> 然后发现可以自动补全Git命令，所以可以把这一加在自己的<em>.bashrc</em>文件中或直接在<em>/etc/bashrc</em>中添加以下  </p>
<pre><code>    <span class="keyword">for</span> file <span class="keyword">in</span> /etc/bash_completion.d/* ; <span class="keyword">do</span>
            <span class="built_in">source</span> <span class="string">"<span class="variable">$file</span>"</span> 
    <span class="keyword">done</span>
</code></pre><h2 id="日志">日志</h2>
<h2 id="基本概念">基本概念</h2>
]]></content>
    
    
      <category term="git" scheme="http://www.migle.me/tags/git/"/>
    
      <category term="工具" scheme="http://www.migle.me/categories/%E5%B7%A5%E5%85%B7/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[DB2笔记]]></title>
    <link href="http://www.migle.me/post/db2%E7%AC%94%E8%AE%B0/"/>
    <id>http://www.migle.me/post/db2笔记/</id>
    <published>2014-01-07T08:48:03.000Z</published>
    <updated>2014-05-12T08:49:20.000Z</updated>
    <content type="html"><![CDATA[<h2 id="基本命令">基本命令</h2>
<ol>
<li>查看DB2版本信息：<code>db2level</code> </li>
<li><p>连接: <code>db2 connect to dbname [user username using password]</code></p>
<blockquote>
<blockquote>
<p>dbname是编目的数据库别名，编目信息可以参考下一节,可以通过<code>db2 list database directory</code> 来查看你可以连接到那些数据库,缺省username和password时用操作系统当前用户连接<br>如果连接成功会有提示,连接成功后： 可以用 <code>db2 -tsvf  /path/sql.sql</code> 来执行一个sql脚本,出错停止，或通过 <code>db2 &quot;select * from table_name &quot;</code> 来执行一句SQL。<br>db2 可支持选项<code>db2 ? OPTIONS</code><br><strong>注意</strong>：如果是Windows系统的话，需要以<code>db2cmd</code>启动命令行窗口,否则会有错误提示:<em>未初始化命令行环境</em></p>
</blockquote>
</blockquote>
</li>
<li><p>db2 shell:<br>执行<code>db2</code> 进行db2交互Shell，再<code>connect to db2 ......</code>，在db2 shell中执行命令或SQL语句也不需要加前缀<code>db2</code>了，执行的命令也不需要用引号</p>
</li>
<li><p>查看SQLCODE对应的详细说明：<code>db2 ? sql-911</code></p>
</li>
<li><p>导出数据库DDL:<code>db2look -d dbname  -I username  -W password -e -a  -o /path/filename</code></p>
<ul>
<li>-d db2name ：指定数据库名，这是必须的</li>
<li>-e: 抽取复制数据所需的DDL文件</li>
<li>-a: 全部对象，可以用-z 来指定schema</li>
<li>-o:导出文件名</li>
<li>-I,-W用来指定用户名字和密码,省略的话会用操作当前用户</li>
<li>更多选项请:<code>db2look -h</code></li>
</ul>
</li>
<li><p>数据导出/导入 </p>
<ul>
<li>export  <pre><code> `export <span class="keyword">to</span> data.csv <span class="keyword">of</span> del <span class="keyword">select</span> * <span class="keyword">from</span> pt.area`  
</code></pre></li>
<li>import  <pre><code>`<span class="keyword">import</span> <span class="keyword">from</span> data.csv of <span class="keyword">del</span> insert into pt.area`   
</code></pre></li>
<li>load  <pre><code>`<span class="operator"><span class="keyword">load</span> <span class="keyword">from</span> data.csv <span class="keyword">of</span> del <span class="keyword">insert</span> <span class="keyword">into</span> pt.area<span class="string">`  </span></span>
</code></pre></li>
<li><p><strong>load from cursor</strong>  </p>
<pre><code>  db2 <span class="keyword">connect</span> to <span class="variable">$target_db_node</span> user <span class="variable">$target_db_user</span> using <span class="variable">$target_db_passwd</span>  
  db2 <span class="string">"DECLARE <span class="variable">$cursor_name</span> CURSOR DATABASE <span class="variable">$source_db_node</span> USER <span class="variable">$source_db_user</span> USING <span class="variable">$source_db_passwd</span>  FOR <span class="variable">$sql</span>"</span>
  db2 <span class="string">"LOAD FROM <span class="variable">$cursor_name</span> OF CURSOR MESSAGES <span class="variable">$log</span> INSERT INTO <span class="variable">$target_table</span>"</span>  
</code></pre></li>
</ul>
</li>
<li><p>表空间查看  </p>
<pre><code> <span class="tag">db2</span> <span class="tag">list</span> <span class="tag">tablespaces</span> <span class="attr_selector">[show detail ]</span>  
</code></pre></li>
</ol>
<h2 id="编目信息">编目信息</h2>
<ol>
<li><p>查看本地编目信息:</p>
<blockquote>
<blockquote>
<p>简单来说就是以本地为客户端能连接到那些服务器上</p>
<ol>
<li>查看节点信息：<code>db2 list node directory</code></li>
<li>查看数据信息：<code>db2 list database directory</code></li>
</ol>
</blockquote>
</blockquote>
</li>
<li><p>编目数据库</p>
<blockquote>
<blockquote>
<p>简单来说，想要以本机为客户端连接到那些服务器上，需要先做下声明</p>
<ol>
<li>编目结点：<code>db2 catalog tcpip node db2node remote hostIP server service_port</code></br></li>
<li>编目数据库:<code>db2 catalog database db_name as alias_name at node db2node</code></li>
<li>eg:<br> 编目结点：<code>db2 catalog tcpip node TVGOPDB remote 135.191.27.175 server 50001</code><br> 编目数据库：<code>db2 catalog database vgopdb as tvgopdb at node tvgopdb</code><br> 测试:<code>db2 connect to tvgopdb</code> </li>
</ol>
</blockquote>
</blockquote>
</li>
<li><p>删除编目 <strong>我没用过！！</strong></p>
<ol>
<li>删除结点编目结点：db2 uncatalog node nodename</li>
<li>删除数据库编目：db2 uncatalog database  databasename</li>
</ol>
</li>
</ol>
<blockquote>
<blockquote>
<p>关于编目内容很多，概念涉及到DB2的体系结构，相关命令也不止上面提到的这些，有机会再完善，目前就只用到这么多</p>
</blockquote>
</blockquote>
<h2 id="表空间">表空间</h2>
<ol>
<li>查看表空间 <code>db2 list tablespaces [show detail ]</code><blockquote>
<blockquote>
<p>show detail的时候请注意这几个字段的值:<em>Total pages</em>,<em>Useable pages</em>,<em>Used pages</em>,<em>Free pages</em>,<em>Page size</em>;<br>(XX pages)*(page size) == XX 大小，注意单位，应该对应的是每个节点的大小</p>
</blockquote>
</blockquote>
</li>
</ol>
<ol>
<li>查看库中的表:<ol>
<li><code>db2 list tables for all</code></li>
<li><code>db2 list tables for schema vgopportal|more</code></li>
<li>列出系统表：<code>db2 list tables for system</code></li>
</ol>
</li>
</ol>
<ol>
<li><p><code>db2 list applications  [show detail ]</code></p>
</li>
<li><p>查看数据库配置信息 <code>db2 get db cfg for vgopdb</code></p>
</li>
<li><p>runstats <code>db2 runstats   on   table   vgopportal.new_kpi_daily   and index all</code></p>
<blockquote>
<blockquote>
<p>runstats可以搜集表的信息，也可以搜集索引信息。作为runstats本身没有优化的功能，<br>但是它更新了统计信息以后，可以让DB2优化器使用最新的统计信息来进行优化，这样优化的效果更好。<br>Quest等客户端中直接<code>runstats   on   table   vgopportal.new_kpi_daily  and index all</code></p>
</blockquote>
</blockquote>
</li>
<li><p><code>db2 force applications all</code> || <code>db2 &quot;force application(handle id)&quot;</code>  ——-Application handle,对应SYSIBMADM.SNAPLOCK表中的agent_id</p>
</li>
</ol>
<h2 id="查看数据各结果分布点况">查看数据各结果分布点况</h2>
<p>SELECT DBPARTITIONNUM(mbuser_id),count(mbuser_id) FROM nwh.mbuser   GROUP BY DBPARTITIONNUM( mbuser_id)</p>
<h2 id="应用">应用</h2>
<h3 id="查看表空间：">查看表空间：</h3>
<pre><code>    db2 <span class="keyword">list</span> tablespaces show detail | more
</code></pre><h3 id="统计所有节点表空间使用率">统计所有节点表空间使用率</h3>
<pre><code>    <span class="operator"><span class="keyword">select</span> 
        substr(TABLESPACE_NAME,<span class="number">1</span>,<span class="number">20</span>) <span class="keyword">as</span> TBSPC_NAME,*
        bigint(TOTAL_PAGES * PAGE_SIZE)/<span class="number">1024</span>/<span class="number">1024</span> <span class="keyword">as</span> <span class="string">"TOTAL(MB)"</span>,
        used_pages*PAGE_SIZE/<span class="number">1024</span>/<span class="number">1024</span> <span class="keyword">as</span> <span class="string">"USED(MB)"</span>, 
        free_pages*PAGE_SIZE/<span class="number">1024</span>/<span class="number">1024</span> <span class="keyword">as</span> <span class="string">"FREE(MB)"</span> 
    <span class="keyword">from</span>
         <span class="keyword">table</span>(snapshot_tbs_cfg(<span class="string">'VGOPDB'</span>, -<span class="number">2</span>)) <span class="keyword">as</span> snapshot_tbs_cfg</span>
</code></pre><h3 id="查看表空间使用率_不分结点">查看表空间使用率   不分结点</h3>
<pre><code>    <span class="operator"><span class="keyword">select</span> 
        substr(tbsp_name,<span class="number">1</span>,<span class="number">20</span>) <span class="keyword">as</span> TABLESPACE_NAME,
        substr(tbsp_content_type,<span class="number">1</span>,<span class="number">10</span>) <span class="keyword">as</span> TABLESPACE_TYPE,
        <span class="aggregate">sum</span>(tbsp_total_size_kb)/<span class="number">1024</span> <span class="keyword">as</span> TOTAL_MB,
        <span class="aggregate">sum</span>(tbsp_used_size_kb)/<span class="number">1024</span> <span class="keyword">as</span> USED_MB,
        <span class="aggregate">sum</span>(tbsp_free_size_kb)/<span class="number">1024</span> <span class="keyword">as</span> FREE_MB,
        tbsp_page_size <span class="keyword">AS</span> PAGE_SIZE <span class="keyword">from</span> 
    SYSIBMADM.TBSP_UTILIZATION 
        <span class="keyword">group</span> <span class="keyword">by</span> tbsp_name,
        tbsp_content_type,
        tbsp_page_size
    <span class="keyword">order</span> <span class="keyword">by</span> <span class="number">1</span></span>
</code></pre><h2 id="系统表">系统表</h2>
<pre><code><span class="comment">syscat</span><span class="string">.</span><span class="comment">tables</span> <span class="literal">-</span><span class="literal">-</span><span class="literal">-</span><span class="comment">fpages</span> <span class="comment">表所占的页数据</span> <span class="comment">乘表空间的页大小后等于该表占的空间，runstatus后才能看有，否则为</span><span class="literal">-</span><span class="comment">1或0</span>
</code></pre><h2 id="db2锁">db2锁</h2>
<ol>
<li>查看锁<br><strong>sql</strong>: <code>SELECT * FROM SYSIBMADM.SNAPLOCK</code><br><strong>命令</strong>: <code>db2 get snapshot for locks on vgopdb</code><br> <em>List Of Locks:…. 就是锁表了的地方</em>  </li>
</ol>
<p><em>这两种方式的结果有什么差异我没有仔细比对过，但SQL方式在qhbidb上执行出错，估计是要用实例用户执行吧，不是很清楚</em>  </p>
<ol>
<li>解锁：<br>如果出现-911的错的时候，下面的语句您可能会用到:   <pre><code> db2pd <span class="attribute">-db</span> vgopdb <span class="attribute">-apinfo</span> handle_id  
 db2 <span class="string">"force application(handle id)"</span>   <span class="subst">--</span>Application <span class="keyword">handle</span>,对应SYSIBMADM<span class="built_in">.</span>SNAPLOCK表中的agent_id
</code></pre></li>
</ol>
<p><a href="http://publib.boulder.ibm.com/infocenter/db2luw/v9/index.jsp?topic=%2Fcom.ibm.db2.udb.admin.doc%2Fdoc%2Fr0021992.htm" target="_blank">http://publib.boulder.ibm.com/infocenter/db2luw/v9/index.jsp?topic=%2Fcom.ibm.db2.udb.admin.doc%2Fdoc%2Fr0021992.htm</a></p>
<hr>
<h2 id="DB2_SQL">DB2 SQL</h2>
<h3 id="创建">创建</h3>
<pre><code>    <span class="operator"><span class="keyword">create</span> <span class="keyword">table</span> target_table <span class="keyword">as</span> (<span class="keyword">select</span> col_1,col_2,col_2 <span class="keyword">from</span> template_table)  definition <span class="keyword">only</span>
    <span class="keyword">create</span> <span class="keyword">table</span> target_table <span class="keyword">like</span>  template_table 
    **注意表空间**</span>
</code></pre><h3 id="_字符串">　字符串</h3>
<pre><code>    <span class="keyword">values</span> <span class="string">'aa'</span>||<span class="string">'bb'</span>
    <span class="keyword">values</span> concat(<span class="string">'aa'</span>,<span class="string">'bb'</span>)
</code></pre><p>特殊符:<code>values &#39;aa&#39;||chr(13)||chr(10)||&#39;bb&#39;</code></p>
<p>上月一号：current date - 1 months -  (day(current date) -1) days</p>
<h3 id="update">update</h3>
<pre><code>    <span class="operator"><span class="keyword">update</span> (<span class="keyword">select</span> * <span class="keyword">from</span> <span class="keyword">where</span> col_1 = vlaue_1) <span class="keyword">set</span> col_2 = value_2</span>
</code></pre><p>查看那些行被更新了(结果为更新后的值):<code>SELECT * FROM FINAL TABLE (UPDATE USER SET SALARY=SALARY*(1+0.2) WHERE SALARY&lt;=2000 )</code><br>把 FINAL TABLE 换成OLD ABLE就是更新前的值，另外把上面的 UPDATE 语句换成 INSERT 和 DELETE 语句同样适用</p>
<h3 id="delete">delete</h3>
<h3 id="清空表:">清空表:</h3>
<pre><code>1. 先<span class="operator"><span class="keyword">drop</span>再<span class="keyword">create</span>
<span class="number">2.</span> 清空: <span class="keyword">alter</span> <span class="keyword">table</span> activate <span class="keyword">not</span> logged <span class="keyword">initially</span> <span class="keyword">with</span> empty <span class="keyword">table</span> </span>
</code></pre><h3 id="多字段：">多字段：</h3>
<ol>
<li><code>SELECT * FROM TABLE_NAME WHERE (col_1,col_2)=(value_1,value_2);</code></li>
<li><code>SELECT * FROM TABLE_NAME WHERE (col_1,col_2) in (select col_1,col_2 from TABLE_NAME_2);</code></li>
<li><code>update TABLE_NAME set (col_1,col_2) = (value_1,value_2)</code></li>
<li><code>update TABLE_NAME set (col_1,col_2) = (select col_1,col_2 from TABLE_NAME_2 where TABLE_NAME.XX = TABLE_NAME_2.XX) where</code></li>
</ol>
<h3 id="order_by">order by</h3>
<h3 id="Merge">Merge</h3>
<h3 id="GROUPING_SETS、ROLLUP、CUBE">GROUPING SETS、ROLLUP、CUBE</h3>
<h3 id="SOME，ANY，All，EXISTS，IN">SOME，ANY，All，EXISTS，IN</h3>
<h3 id="UNION_[ALL],_INTERSECT_[ALL],_EXCEPT_[ALL]">UNION [ALL], INTERSECT [ALL], EXCEPT [ALL]</h3>
<h3 id="分页排序">分页排序</h3>
<ol>
<li>有同值的行时order by 顺序有可能不一致</li>
<li>前10行:<code>SELECT * FROM &lt;TABLE_NAME&gt; ORDER BY 1 FETCH FIRST 10 ROWS ONLY ;</code></li>
<li>随机取前10行:<code>SELECT * FROM &lt;TABLE_NAME&gt; ORDER BY RAND() FETCH FIRST 10 ROWS ONLY ;</code></li>
<li>从 staff 表中，采用 BERNOULLI 抽样方法，抽取 8%的样本数据，REPEATABLE 表示多次执行相同的语句返回相同的结果:<code>SELECT * FROM staff TABLESAMPLE BERNOULLI(8) REPEATABLE(586) ORDER BY id;</code><blockquote>
<blockquote>
<p>1、BERNOULLI(行级别伯努利采样)：它检查每一行，准确率高，但是性能差。<br>2、SYSTEM(系统页级采样)：它检查每一数据页(一个数据页包含若干行)，性能高，但准确率差</p>
</blockquote>
</blockquote>
</li>
</ol>
<h3 id="隔离级别">隔离级别</h3>
<ol>
<li>可重复读（RR）</li>
<li>读稳定性（RS）</li>
<li>游标稳定性（CS）—-默认的隔离级别</li>
<li>未落实的读（UR）</li>
</ol>
<h4 id="常用函数">常用函数</h4>
<h3 id="坑：">坑：</h3>
<ol>
<li>select * from TABLENAME where col1 in(select distinct col2 from TABLENAME2)   —-是需要加distinct</li>
<li>能把where中的OR换成in可以换成in</li>
<li>尽量少在where 条件或关联的时候少用<strong>函数转换</strong></li>
<li>where中尽量少用或不用<strong>like</strong></li>
</ol>
<h3 id="其它">其它</h3>
<p>第一：SQL 语句执行的顺序</p>
<ol>
<li>FROM</li>
<li>JOIN ON</li>
<li>WHERE</li>
<li>GROUP BY</li>
<li>HAVING</li>
<li>SELECT</li>
<li>ORDER BY</li>
<li>FETCH FIRST</li>
</ol>
<p>   <code>db2 catalog tcpip node QHBIDB remote 135.191.27.50 server 50000</code> </br><br>        <code>db2 catalog database QHBIDB as QHBIDB at node QHBIDB</code>       </p>
<pre><code>    <span class="escape">`d</span>b2 catalog tcpip node MVGOPDB remote <span class="number">135.191</span>.<span class="number">27.170</span> server <span class="number">50001</span><span class="escape">` </span>  
    <span class="escape">`d</span>b2 catalog database vgopdb as mvgopdb at node mvgopdb`
</code></pre><h2 id="应用程序开发">应用程序开发</h2>
<h3 id="Java">Java</h3>
<p>没什么说的，注意jdbc驱动和Tomcat7有点冲突,后面的版本再没测过</p>
<h3 id="Python">Python</h3>
<hr>
<p>用过的db2驱动有<a href="https://code.google.com/p/pyodbc/" target="_blank">pyodbc</a> 和 <a href="https://code.google.com/p/ibm-db/" target="_blank">ibm_db</a><br><strong>pyodbc</strong>的通用性要好一些,安装方便，实现了DB-API 2.0 specification 性能估计没有ibm_db好，Windows下各版都有编译好的包可以安装,详细内容可以参见:<a href="https://code.google.com/p/pyodbc/" target="_blank">https://code.google.com/p/pyodbc/</a><br><strong>ibm_db</strong>性能应该会好些,是DB2 API的Python包装，所以你可能还需要至少装上(IBM Data Server Driver Package)[<a href="https://www-304.ibm.com/support/docview.wss?uid=swg27016878" target="_blank">https://www-304.ibm.com/support/docview.wss?uid=swg27016878</a>] , 另外还有一个ibm_db_dbi 也是对DB-API 2.0 specification的实现，如果能连网的话可以直接用easy_install安装<code>easy_install ibm_db</code>，如果不能连网，就用签出源码自己编译吧，<em>下次安装的时候再补充</em><br>这两个包项目主页都有很详细的说明，自己看吧，这里就不复制粘贴了</p>
<h3 id="SHELL">SHELL</h3>
<hr>
<pre><code><span class="function"><span class="title">connDB2</span></span>()
{
    db2 connect to <span class="variable">$1</span>  user <span class="variable">$2</span> using <span class="variable">$3</span> &gt; /dev/null )b
    <span class="keyword">then</span> 
        <span class="built_in">echo</span> <span class="string">'连接成功'</span>
    <span class="keyword">else</span>
        <span class="built_in">echo</span> <span class="string">"连接失败"</span>
    <span class="keyword">exit</span> -<span class="number">1</span>
    <span class="keyword">fi</span>
}

connDB2 <span class="variable">${DBNODE}</span> <span class="variable">${DBUSER}</span> <span class="variable">${DBPASSWORD}</span>
sql=<span class="string">"
    select 
        area_id ,areaname
    from 
        pt.area"</span>

<span class="comment">##循环读取数据</span>
db2 -x <span class="variable">${sql}</span>| <span class="keyword">while</span> <span class="built_in">read</span> area_id areaname  
<span class="keyword">do</span>  
    <span class="built_in">echo</span> <span class="string">"Result:<span class="variable">${area_id}</span>-&gt;<span class="variable">${areaname}</span>"</span>  
<span class="keyword">done</span>
<span class="comment">##读取单个值</span>
ISEXISTS=$(db2 -x <span class="string">"select count(1) from SYSIBM.SYSTABLES where lower(name) =lower('user_user') and lower(creator)=lower('vgopportal') with ur"</span>)

   <span class="comment">##update </span>
db2 -x <span class="string">"update pt.area set area_id=123 where area_id=456"</span>

<span class="comment">##export</span>
db2 <span class="string">"export to tb_dpi_20131025_00_01.dat   of del select * from NIPD.V_SERVICE_INFO_20131025 "</span>
</code></pre><p>注意每一次执行db2命令后，你可能还需要进行类似下面的语句进行错误处理，否则会有问题</p>
<pre><code><span class="keyword">if</span> [ <span class="string">"$?"</span> <span class="operator">-ne</span> <span class="string">"0"</span> ]  
<span class="keyword">then</span>
    <span class="built_in">echo</span> <span class="string">"执行出现错误所以退出"</span>  
    <span class="keyword">exit</span> -<span class="number">1</span>
<span class="keyword">else</span>
    <span class="built_in">echo</span> <span class="string">"执行成功了"</span>
<span class="keyword">fi</span> 
</code></pre><blockquote>
<blockquote>
<p>返回值代码及说明如下：<br>0     DB2 command or SQL statement executed successfully<br>1     SELECT or FETCH statement returned no rows<br>2     DB2 command or SQL statement warning<br>4     DB2 command or SQL statement error<br>8     Command line processor system error  </p>
</blockquote>
</blockquote>
<p><a href="http://publib.boulder.ibm.com/infocenter/db2luw/v8/topic/com.ibm.db2.udb.doc/core/r0010411.htm" target="_blank">返回值官方说明</a></p>
<h3 id="C/C++">C/C++</h3>
<p>这个你来补吧，太煎熬了，我应该不会用到这，感兴趣可以看看DB2自带的例子程序SQLLIB\samples\ :(</p>
]]></content>
    
    
      <category term="DB2" scheme="http://www.migle.me/tags/DB2/"/>
    
      <category term="数据库" scheme="http://www.migle.me/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Markdown笔记]]></title>
    <link href="http://www.migle.me/post/markdown%E7%AC%94%E8%AE%B0/"/>
    <id>http://www.migle.me/post/markdown笔记/</id>
    <published>2013-06-12T03:24:21.000Z</published>
    <updated>2014-05-13T02:29:35.000Z</updated>
    <content type="html"><![CDATA[<h2 id="markdown_简述">markdown 简述</h2>
<blockquote>
<p>Markdown 的语法全由一些符号所组成，这些符号经过精挑细选，其作用一目了然。比如：在文字两旁加上星号，看起来就像<em>强调</em>。Markdown 的列表看起来，嗯，就是列表。Markdown 的区块引用看起来就真的像是引用一段文字，就像你曾在电子邮件中见过的那样。</p>
<p>Markdown 语法的目标是：成为一种适用于网络的书写语言。</p>
<p>Markdown 不是想要取代 HTML，甚至也没有要和它相近，它的语法种类很少，   只对应 HTML 标记的一小部分。Markdown 的构想不是要使得 HTML 文档更容易书写。在我看来， HTML 已经很容易写了。Markdown 的理念是，能让文档更容易读、写和随意改。HTML 是一种发布的格式，Markdown 是一种书写的格式。就这样，Markdown 的格式语法只涵盖纯文本可以涵盖的范围。</p>
<p>不在 Markdown 涵盖范围之内的标签，都可以直接在文档里面用 HTML 撰写。不需要额外标注这是 HTML 或是 Markdown；只要直接加标签就可以了。</p>
<p>要制约的只有一些 HTML 区块元素――比如 <code>&lt;div&gt;,&lt;table&gt;,&lt;pre&gt;,&lt;p&gt;</code><br>等标签，必须在前后加上空行与其它内容区隔开，还要求它们的开始标签与结尾标签不能用制表符或空格来缩进。Markdown 的生成器有足够智能，不会在 HTML 区块标签外加上不必要的 <code>&lt;p&gt;</code> 标签。</p>
<p>在 HTML 区块标签间的 Markdown 格式语法将不会被处理。比如，你在 HTML 区块内使用 Markdown 样式的<em>强调</em>会没有效果。</p>
<p>HTML 的区段（行内）标签如 <code>&lt;span&gt;、&lt;cite&gt;、&lt;del&gt;</code> 可以在 Markdown 的段落、列表或是标题里随意使用。依照个人习惯，甚至可以不用 Markdown 格式，而直接采用 HTML 标签来格式化。举例说明：如果比较喜欢 HTML 的 <code>&lt;a&gt; 或 &lt;img&gt;</code>标签，可以直接使用这些标签，而不用 Markdown 提供的链接或是图像标签语法。</p>
<p>和处在 HTML 区块标签间不同，Markdown 语法在 HTML 区段标签间是有效的。</p>
</blockquote>
<h2 id="标题">标题</h2>
<h2 id="列表">列表</h2>
<h3 id="Markdown_支持有序列表和无序列表。">Markdown 支持有序列表和无序列表。</h3>
<ul>
<li><p>无序列表使用星号、加号或是减号作为列表标记:<em>\</em>、+、-*：</p>
</li>
<li><p>有序列表则使用数字接着一个英文句点：</p>
</li>
<li><p>列表项目可以包含多个段落，每个项目下的段落都必须缩进 4 个空格或是 1 个制表符</p>
</li>
</ul>
<h2 id="代码块">代码块</h2>
<pre><code>缩进4个空格或一个制表符
在生成HTML时会用 <span class="tag">&lt;<span class="title">pre</span>&gt;</span> 和 <span class="tag">&lt;<span class="title">code</span>&gt;</span> 标签来把代码区块包起来
代码区块中，一般的 Markdown 语法不会被转换，像是星号便只是星号，这表示你可以很容易地以 Markdown 语法撰写 Markdown 语法相关的文件。
一个代码区块会一直持续到没有缩进的那一行（或是文件结尾）
如果要标记一小段行内代码，你可以用反引号把它包起来(`)
如果要在代码区段内插入反引号，你可以用多个反引号来开启和结束代码区段：
</code></pre><h2 id="链接">链接</h2>
<p>Markdown 支持两种形式的链接语法链接地址形式有HTML中的A是一样，可以是外部地址，也可以本机地址： 行内式和参考式两种形式。</p>
<ul>
<li>文本链接</li>
</ul>
<pre><code>要建立一个行内式的链接，只要在方块括号后面紧接着圆括号并插入网址链接即可，如果你还想要加上链接的 title 文字，只要在网址后面，用双引号把 title 文字包起来即可，例如：
</code></pre><p>This is <a href="http://example.com/" title="Title" target="_blank">an example</a> inline link.</p>
<pre><code>[<span class="link_label">This link</span>](<span class="link_url">http://example.net/</span>) has no title attribute.

 参考式的链接是在链接文字的括号后面再接上另一个方括号，而在第二个方括号里面要填入用以辨识链接的标记：

 This is [<span class="link_label">an example</span>][<span class="link_reference">id</span>] reference-style link.
 你也可以选择性地在两个方括号中间加上一个空格：

 This is [an example] [id] reference-style link.
 接着，在文件的任意处，你可以把这个标记的链接内容定义出来：
</code></pre><ul>
<li>图片链接,<ol>
<li>行内式<br><code>![Alt text](/path/to/img.jpg)</code><br><code>![Alt text](/path/to/img.jpg &quot;Optional title&quot;)</code><br>2.和参考式。<br><code>·![Alt text][id]</code><br> 「id」是图片参考的名称，图片参考的定义方式则和连结参考一样：<br><code>[id]: url/to/image  &quot;Optional title attribute&quot;</code></li>
</ol>
</li>
<li>自动链接<br>  <code>&lt;http://example.com/&gt;</code></li>
</ul>
<h2 id="强调">强调</h2>
<p>Markdown 使用星号（<em>）和底线（_）作为标记强调字词的符号，被 </em> 或 <em> 包围的字词会被转成用 <code>&lt;em&gt;</code> 标签包围，用两个 * 或 \</em> 包起来的话，则会被转成 <code>&lt;strong&gt;</code><br>但是如果你的 * 和 _ 两边都有空白的话，它们就只会被当成普通的符号。</p>
<h2 id="分隔线">分隔线</h2>
<p>你可以在一行中用三个以上的星号、减号、底线来建立一个分隔线，行内不能有其他东西。你也可以在星号或是减号中间插入空格。下面每种写法都可以建立分隔线：</p>
<h2 id="参考资料">参考资料</h2>
<p><a href="http://wowubuntu.com/markdown/" target="_blank">Markdown 语法说明 (简体中文版)</a></p>
<p>测试一下代码块</p>
<pre><code><span class="comment">#encoding: utf-8</span>
<span class="comment">=begin
这里的就是内嵌文档，相当于Java doc
=end</span>
<span class="class"><span class="keyword">class</span> <span class="title">FirstClass</span></span>
    <span class="keyword">attr_accessor</span> <span class="symbol">:name</span> <span class="comment">#可以在修改类定义的时候加上</span>

    <span class="function"><span class="keyword">def</span> </span>initialize(name=<span class="string">"migle"</span>)
        <span class="variable">@name</span> = name
    <span class="keyword">end</span>

    <span class="function"><span class="keyword">def</span> </span>sayHi
        puts <span class="string">"中文可以不：Hi <span class="subst">#{<span class="variable">@name</span>}</span>"</span>
    <span class="keyword">end</span> 
<span class="keyword">end</span>
<span class="keyword">if</span> __FILE_<span class="number">_</span> == <span class="variable">$0</span>
    m = <span class="constant">FirstClass</span>.new(<span class="string">"Miyong"</span>)
    m.sayHi
    a=<span class="string">'米哥'</span>
    puts m.respond_to?(<span class="string">"name"</span>)
    puts m.respond_to?(<span class="string">"name="</span>)
    <span class="comment">#class FirstClass    #这里可以修改类定义</span>
    <span class="comment">#    attr_accessor :name</span>
    <span class="comment">#end</span>
    m.name = <span class="string">"Mike"</span>
    m.sayHi
<span class="keyword">end</span>
</code></pre><p>语法高亮</p>
]]></content>
    
    
      <category term="Markdown" scheme="http://www.migle.me/tags/Markdown/"/>
    
      <category term="其它" scheme="http://www.migle.me/categories/%E5%85%B6%E5%AE%83/"/>
    
  </entry>
  
</feed>
